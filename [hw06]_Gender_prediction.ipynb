{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[hw06] Gender prediction",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jes000510/pub/blob/main/%5Bhw06%5D_Gender_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqQfG6JF2v1M"
      },
      "source": [
        "참여자 명단:  강은수(영어영문학과),  조재영(언어학과)\n",
        "\n",
        "이 과제의 목적은 주어진 영어 이름의 성별을 예측하는 모형을 만드는 것이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEwSMJSGHjcb"
      },
      "source": [
        "# Preperation\n",
        "\n",
        "`pandas`, `gensim` 및 `torch` 라이브러리를 가져온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWHO7X6hvxqj"
      },
      "source": [
        "# for reading a dataset\n",
        "import pandas as pd\n",
        "\n",
        "# for pre-training an embedding\n",
        "from gensim.models import FastText\n",
        "\n",
        "# for building and training neural networks\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kStY9GZIej0"
      },
      "source": [
        "# Corpus\n",
        "\n",
        "[Gender by Name](https://archive.ics.uci.edu/ml/datasets/Gender+by+Name)이라는 데이터 파일을 내려받는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGdXFmAPtqFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4571a1-2db0-47f2-a12f-4f759fe43867"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00591/name_gender_dataset.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 07:35:50--  https://archive.ics.uci.edu/ml/machine-learning-databases/00591/name_gender_dataset.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3774591 (3.6M) [application/x-httpd-php]\n",
            "Saving to: ‘name_gender_dataset.csv’\n",
            "\n",
            "name_gender_dataset 100%[===================>]   3.60M  6.58MB/s    in 0.5s    \n",
            "\n",
            "2021-04-28 07:35:51 (6.58 MB/s) - ‘name_gender_dataset.csv’ saved [3774591/3774591]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqfbD6M7uDpN"
      },
      "source": [
        "`pandas`  라이브러리의 `read.csv()`  함수를 사용하면 csv 파일을 읽을 수 있다.\n",
        "`DataFrame.head()`  메소드로 첫 부분을 살펴보면 Name, Gender, Count, Probability  네 개의 필드로 이루어져 있다. 데이터(Name)와 정답(Gender)이 모두 있으므로 신경망 지도 학습이 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Fv5oGXibHknQ",
        "outputId": "ac7dc41b-fcba-4968-d2ba-3bc91659f56b"
      },
      "source": [
        "data = pd.read_csv('name_gender_dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Count</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James</td>\n",
              "      <td>M</td>\n",
              "      <td>5304407</td>\n",
              "      <td>0.014517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John</td>\n",
              "      <td>M</td>\n",
              "      <td>5260831</td>\n",
              "      <td>0.014398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Robert</td>\n",
              "      <td>M</td>\n",
              "      <td>4970386</td>\n",
              "      <td>0.013603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Michael</td>\n",
              "      <td>M</td>\n",
              "      <td>4579950</td>\n",
              "      <td>0.012534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>William</td>\n",
              "      <td>M</td>\n",
              "      <td>4226608</td>\n",
              "      <td>0.011567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Name Gender    Count  Probability\n",
              "0    James      M  5304407     0.014517\n",
              "1     John      M  5260831     0.014398\n",
              "2   Robert      M  4970386     0.013603\n",
              "3  Michael      M  4579950     0.012534\n",
              "4  William      M  4226608     0.011567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCylISlbIn9W"
      },
      "source": [
        "각 이름을 벡터로 표현하기 위해서는 단어 임베딩 모형이 필요하다.  임베딩 모형을 훈련하기 위한 코퍼스는 문장(단어들의 리스트)들의 리스트로 표현한다. 여기에서는 이름 하나를 문장 하나로 취급한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai8B4QmBIkKD"
      },
      "source": [
        "names = list(data['Name']) # list of names\n",
        "names = [[name] for name in names] # list of lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAVW_aejHcfv"
      },
      "source": [
        "# Pre-training a word embedding\n",
        "\n",
        "주어진 코퍼스로부터 단어들을 각각 100차원 벡터로 임베딩하는 `FastText` 모형을 훈련시킨다. 훈련과 관련된 하이퍼패러미터들의 값은 이후 검증 집합에서의 성능을 살펴보면서 변경할 수 있다. `help(FastText)`로 알아보라."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACqFAzpHvunH"
      },
      "source": [
        "embeddings = FastText(sentences=names, sg=1, min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1I-5ahLvD0V"
      },
      "source": [
        "### [Q1] FastText와 Word2Vec의 공통점과 차이점을 조사해서 쓰라.  (5점)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElZpQgRRHq3O"
      },
      "source": [
        "# Building a neural network\n",
        "\n",
        "입력층과 출력층의 차원을 결정하기 위해 단어 임베딩 벡터의 차원(`d`)과 분류할 범주의 개수(`n_classes`)를 변수로 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHKhcwbEyv1l"
      },
      "source": [
        "d = embeddings.wv.vector_size # 100-dimension\n",
        "n_classes = 2  # F/M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wxVsdbPKKwo"
      },
      "source": [
        "은닉층 유닛 개수는 128로 해 보자. 이 값은 이후 검증 집합에서의 성능을 살펴보면서 변경할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iMr-gjTKLJl"
      },
      "source": [
        "# hyperparameter setting\n",
        "hidden_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZGzsY3QKwmt"
      },
      "source": [
        "입력층, 은닉층, 출력층 각 한 개로 이루어진 신경망을 구성하자.\n",
        "\n",
        "+  `fc1`:  입력층-->은닉층. 활성화함수로 ReLU를 사용한다.\n",
        "+  `fc2`: 은닉층-->출력층.  \n",
        "\n",
        "은닉층의 개수는 이후 검증 집합에서의 성능을 살펴보면서 변경할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWbJHfouxtIa"
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(FFNN, self).__init__()\n",
        "    # input -> hidden (fully connected)\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    # hidden -> output (fully connected)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    # He initialization\n",
        "    nn.init.kaiming_uniform_(self.fc1.weight)\n",
        "    # Xavier initialization\n",
        "    nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input -> hidden\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # hidden -> output\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5r4H0PdL8uj"
      },
      "source": [
        "신경망을 `net`이라는 변수로 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ09WIKl-wRo",
        "outputId": "57625249-baae-4851-8597-96fd6de23a39"
      },
      "source": [
        "net = FFNN(input_dim=d, hidden_dim=hidden_size, output_dim=n_classes)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYrQDiQOMsyX"
      },
      "source": [
        "입력 벡터를 실제로 신경망에 넣어서 출력 벡터를 뽑아 보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjlW18suxZgT"
      },
      "source": [
        "###  [Q2] 아래의 코드를 수정하여 'Cyrill'이라는 이름에 해당하는 입력 벡터를 만들라.  (1점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RVko_tt0KT4"
      },
      "source": [
        "input = None # edit this line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YF_RsHFNEw-"
      },
      "source": [
        "입력 벡터는 100차원짜리 단어 벡터 1개로 이루어져 있으므로 100차원이 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSpuYgODNE7e",
        "outputId": "d6cd0204-85f2-4c0e-8d80-88e2a717b82a"
      },
      "source": [
        "print(input.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceRGm79xNUQB"
      },
      "source": [
        "분류할 범주 목록은 {F, M}  두 가지로 이루어져 있으므로 출력 벡터는 2차원이 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSpqIzkvALq8",
        "outputId": "71539ae4-cd99-4f01-ca6a-e3e299ee1a38"
      },
      "source": [
        "output = net(input)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2])\n",
            "tensor([-0.0405,  0.1128], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db4l5lPkNlBv"
      },
      "source": [
        "# Training, validation & test datasets\n",
        "\n",
        "언어 모형의 목적에 맞는 데이터셋을 구성하자. `torch.utils.data.Dataset` 클래스를 상속하여 새 클래스를 만들고, `__len__()` 함수와 `__getitem__()` 함수를 새로 만들면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m92WN0sVyBaF"
      },
      "source": [
        "### [Q3] 아래의 코드를 수정하여 주어진 데이터의 특성에 맞게 `__getitem__()`함수를 정의하라. 변수 `label`의 값은 여성일 때 0, 남성일 때 1이 되도록 만들라.  (2점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZJpZehJLlc"
      },
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, data, embeddings):\n",
        "    self.data = data\n",
        "    self.embeddings = embeddings\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # do something here\n",
        "    embedding = None # edit this line\n",
        "    label = None # edit this line\n",
        "    # do something here\n",
        "    sample = (embedding, label)\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i3-WobAOESg"
      },
      "source": [
        "위와 같은 형식으로 코퍼스에서 데이터셋을 구축한 결과 총 147269개의 데이터가 나왔다.  각 데이터는 100차원의 입력 벡터와 1개의 정답 레이블로 이루어져 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdIRC6o4LmnV",
        "outputId": "fb335864-1720-4977-d84c-6713fdc85bb5"
      },
      "source": [
        "dataset = NameDataset(data=data, embeddings=embeddings)\n",
        "print(len(dataset))\n",
        "print(dataset[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "147269\n",
            "(tensor([-4.1113e-03,  8.8973e-04,  1.0328e-03, -3.3855e-03,  3.6794e-05,\n",
            "         2.2390e-03, -1.8533e-03,  5.7245e-04, -2.5286e-03, -2.0550e-03,\n",
            "         1.4471e-03, -2.3074e-04, -3.1000e-04,  2.4891e-04,  1.1722e-03,\n",
            "         3.7925e-04, -9.8197e-05,  2.6890e-04,  7.1511e-04, -9.3246e-04,\n",
            "         2.2390e-04,  1.0028e-03, -3.1352e-03, -1.9278e-03, -1.2745e-03,\n",
            "        -5.5888e-04,  2.0600e-03,  7.5192e-04, -2.2592e-04, -6.9057e-04,\n",
            "         9.2585e-04,  3.0719e-03,  1.3722e-04, -1.9290e-05, -1.1767e-03,\n",
            "         1.5130e-03, -8.7881e-04, -8.8179e-04,  4.0520e-04,  2.0974e-03,\n",
            "         2.0471e-05,  8.8442e-04,  1.6194e-03,  2.3987e-03, -1.1454e-03,\n",
            "        -8.6900e-04,  1.1137e-03,  5.3693e-04,  3.6724e-03,  3.2615e-04,\n",
            "         9.2433e-04, -3.4728e-03,  4.1074e-04, -2.3824e-03, -5.5873e-04,\n",
            "        -8.6599e-04,  1.1831e-03, -1.8583e-04,  1.9689e-03,  6.1821e-04,\n",
            "         9.0586e-04,  2.6157e-04,  1.2586e-03,  1.0602e-05, -2.2609e-04,\n",
            "         1.3798e-03,  1.8795e-03, -2.7194e-03,  1.1713e-03,  1.9918e-03,\n",
            "         1.8490e-03, -1.4812e-03,  5.9644e-04, -4.1655e-04,  8.0326e-04,\n",
            "         4.3870e-04, -1.5680e-03,  3.0337e-05, -4.8225e-04,  1.7577e-03,\n",
            "        -1.4258e-03,  2.0969e-03,  4.2462e-04,  1.9463e-03, -1.5454e-03,\n",
            "        -1.7528e-03, -1.3739e-03,  1.0776e-03, -3.7826e-04,  2.2348e-03,\n",
            "        -3.6486e-03,  1.4571e-03, -2.4566e-03,  7.2260e-04, -3.5980e-03,\n",
            "        -7.7194e-04,  5.1316e-04, -1.4520e-03,  1.2012e-03, -1.7861e-03]), 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--QqyLScOXsZ"
      },
      "source": [
        "아래 코드에서는\n",
        "\n",
        "1. 배치 사이즈를 32로 설정한다.\n",
        "2. `torch.utils.data.random_split()` 함수로 훈련 집합(120000개),  검증 집합(10000개),  실험 집합(나머지)을 분할한다.\n",
        "3. 각 집합을 한 번에 배치 사이즈만큼 읽어 오는 `DataLoader()` 객체를 만든다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "108AXUOGMcV6"
      },
      "source": [
        "batch_size = 32\n",
        "train_dataset, valid_dataset, test_dataset = random_split(\n",
        "    dataset=dataset,\n",
        "    lengths=[120000, 10000, len(dataset)-130000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZQxOOTYOu_N"
      },
      "source": [
        "# Training & evaluating the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwfhqXNIPSIU"
      },
      "source": [
        "##  Loss function\n",
        "\n",
        "신경망 훈련을 위해 교차 엔트로피 손실함수를 가져온다. 실제로는 먼저 소프트맥스 활성화함수를 적용한 후에 L_CE를 계산하는 구조로 되어 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JXFbZPIO3vw"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgg1RYMtPPiY"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "최적화기를 Adam으로 사용하고 초기 학습률을 0.01로 설정한다. 최적화기와 학습률은 이후 검증 집합에서의 성능을 살펴보면서 변경할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U1dA5jePmoi"
      },
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB5VvZ2tPm2F"
      },
      "source": [
        "## Training & Evaluating\n",
        "\n",
        "손실함수와 최적화기를 사용하여 훈련 집합의 데이터로 신경망의 가중치 매개변수를 업데이트하고, 검증 집합에서의 정확도(accuracy)로 성능을 확인한다. epoch 횟수는 이후 검증 집합에서의 성능을 살펴보면서 변경할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SomO1_4w0Vjf"
      },
      "source": [
        "###  [Q4]  아래의 코드를 수정하여 검증 집합에서 정확도를 계산할 수 있도록 하라.  (2점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyFtzjdDONVH",
        "outputId": "9893810a-1a41-4b86-8a72-3b3fdd6e0437"
      },
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  for inputs, labels in train_loader:\n",
        "    # Load embeddings with gradient accumulation capabilities\n",
        "    inputs = inputs.requires_grad_()\n",
        "\n",
        "    # Clear gradients w.r.t. parameters\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass to get output/logits\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # Calculate Loss: softmax --> cross entropy loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Getting gradients w.r.t. parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating parameters\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate validation accuracy\n",
        "  # do something here\n",
        "  with torch.no_grad():\n",
        "    for (inputs, labels) in valid_loader:\n",
        "        # do something here\n",
        "  accuracy = None # edit this line\n",
        "  print(f'Epoch: {epoch}. Training Loss: {loss.item()}. Validation Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0. Training Loss: 0.7106466293334961. Validation Accuracy: 58.1\n",
            "Epoch: 1. Training Loss: 0.6385602355003357. Validation Accuracy: 62.93\n",
            "Epoch: 2. Training Loss: 0.6616467833518982. Validation Accuracy: 62.34\n",
            "Epoch: 3. Training Loss: 0.6514435410499573. Validation Accuracy: 62.19\n",
            "Epoch: 4. Training Loss: 0.6141008734703064. Validation Accuracy: 62.81\n",
            "Epoch: 5. Training Loss: 0.6198220252990723. Validation Accuracy: 62.77\n",
            "Epoch: 6. Training Loss: 0.6655550599098206. Validation Accuracy: 62.45\n",
            "Epoch: 7. Training Loss: 0.5650405287742615. Validation Accuracy: 62.69\n",
            "Epoch: 8. Training Loss: 0.6531237363815308. Validation Accuracy: 62.65\n",
            "Epoch: 9. Training Loss: 0.6291529536247253. Validation Accuracy: 62.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soYNlQML0pEP"
      },
      "source": [
        "[Q4]와 같은 방식으로 실험 집합에서의 정확도를 계산할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CljkMWRVj_Kl",
        "outputId": "19e1afe7-0c42-4b5b-f00f-2c6da5f5c2b4"
      },
      "source": [
        "# do something here\n",
        "with torch.no_grad():\n",
        "  for (inputs, labels) in test_loader:\n",
        "      # do something here\n",
        "accuracy = None # edit this line\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 62.8589240529539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaGZoARW0zwX"
      },
      "source": [
        "### [Q5] 위에서 언급한 여러 하이퍼패러미터를 조정해 가면서 가능한 한 높은 정확도를 달성하라.  (정확도에 10을 곱하고 소수점 셋째 자리에서 반올림한 값을 점수로 부여한다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElGNK_7AQpip"
      },
      "source": [
        "# Predicting the gender\n",
        "\n",
        "실험 집합에도 없는 새로운 이름에 대해서도 신경망이 잘 작동하는지 확인해 보자.\n",
        "\n",
        "예를 들어 \"Shrek\"이라는 이름은 데이터에 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxqMikAbfa2v",
        "outputId": "b388ab2f-5577-47e9-e4fd-ed9a117fc766"
      },
      "source": [
        "print(['Shrek'] in names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wbyZ-xjpfKc"
      },
      "source": [
        "위에서 훈련된 신경망은 이 이름을 어느 성별로 예측할까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCgilcqp1Tkp"
      },
      "source": [
        "### [Q6] 아래의 코드를 수정하여 \"Shrek\"이 어느 성별로 분류되는지 예측하라. (1점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1YFq4P2FRgY"
      },
      "source": [
        "input = None # edit this line\n",
        "output = net(input)\n",
        "F.softmax(output, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JvOYIqxqAuS"
      },
      "source": [
        "데이터에 없는 다른 이름으로 \"Shica\"에 대해서 같은 방식으로 확률을 구해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_FtC-bPfXSL",
        "outputId": "33d04d49-9e84-46a9-ae61-ea07cfe9f936"
      },
      "source": [
        "print(['Shica'] in names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfLDpm8t1_j2"
      },
      "source": [
        "### [Q7] 아래의 코드를 수정하여 \"Shica\"가 어느 성별로 분류되는지 예측하라.  (1점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9xMciEOfRlI"
      },
      "source": [
        "input = None # edit this line\n",
        "output = net(input)\n",
        "F.softmax(output, -1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}